---
title: "06_CLIF_Prone_Additional_Analyses"
author: "Chad H. Hochberg and Anna K Barker"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Install Following Libraries For this Project
packages_to_install =
  c("tidyverse",
    "tidytable",
    "data.table",
    "collapse",
    "arrow",
    "tableone",
    "viridis",
    "sandwich",
    "lmtest",
    "marginaleffects",
    "yaml",
    "rprojroot")

#Can Load For Each Individual RMarkdown
packages_to_load =
  c(
    "tidyverse",
    "tidytable",
    "data.table",
    "collapse",
    "arrow",
    "tableone",
    "viridis",
    "sandwich",
    "lmtest",
    "marginaleffects",
    "yaml",
    "rprojroot")
options(dplyr.summarise.inform = FALSE)

fn_install_if_mi = function(p) {
  if (!requireNamespace(p, quietly = TRUE)) {
    try(install.packages(p, dependencies = TRUE), silent = TRUE)
  }
}

fn_load_quiet = function(p) {
  suppressPackageStartupMessages(library(p, character.only = TRUE))
}

invisible(lapply(packages_to_install, fn_install_if_mi))
invisible(lapply(packages_to_load,   fn_load_quiet))
options(dplyr.summarise.inform = FALSE)
rm(packages_to_install, packages_to_load, fn_install_if_mi, fn_load_quiet); gc()

#Set Working Directory as the Project Root
project_root <- file.path( find_root(rprojroot::has_dir("CLIF_Proning_Incidence_Severe_ARF")),
  "CLIF_Proning_Incidence_Severe_ARF")
knitr::opts_knit$set(root.dir = project_root)
getwd()

#Load Config and Setting
config = yaml::read_yaml(paste0(project_root, '/config/config.yaml'))

### user entered site details ---------------------------------------------------
site             = tolower(config$site)
file_type        = tolower(config$file_type)  
tables_location  = config$clif_data_path 
project_location = config$project_location
site_time_zone = config$site_time_zone

setwd(project_location)

#Use Dplyr functions as default
filter <- dplyr::filter
mutate <- dplyr::mutate
select <- dplyr::select
arrange <- dplyr::arrange
group_by <- dplyr::group_by
summarise <- dplyr::summarise
lead <- dplyr::lead
lag <- dplyr::lag
coalesce <- dplyr::coalesce
n <- dplyr::n
```

```{r}
check_timezone <- function(site_timezone, intended_timezone = Sys.timezone()) {
  if (site_timezone != intended_timezone) {
    cat("Warning: You specified", site_timezone, "but your system time zone is", intended_timezone, "\n")
    response <- readline(prompt = "Was that intentional? (yes/no): ")
    
    if (tolower(response) %in% c("no", "n")) {
      new_timezone <- readline(prompt = "Please enter the correct timezone: ")
      cat("Timezone updated to", new_timezone, "\n")
      return(new_timezone)
    } else {
      cat("Proceeding with the originally specified timezone:", site_timezone, "\n")
      return(site_timezone)
    }
    
  } else {
    cat("Timezone is set to", site_timezone, "\n")
    return(site_timezone)
  }
}


#Time Zone Check
result <- check_timezone(site_time_zone)

setwd(project_location)
```





```{r Optimize Use of Cores - Code from Pat Lyons}
### threads and ram ------------------------------------------------------------

os_type   = Sys.info()[["sysname"]]
all_cores = parallel::detectCores(logical = TRUE)
all_cores = if (is.na(all_cores)) 1L else as.integer(all_cores)

get_ram_gb = function() {
  tryCatch({
    if (os_type == "Darwin") {
      # macOS: sysctl reports total RAM in bytes
      bytes = suppressWarnings(
        as.numeric(system("sysctl -n hw.memsize", intern = TRUE))
      )
      if (length(bytes) > 0 && !is.na(bytes)) bytes / 1024^3 else NA_real_
    } else {
      # Windows & Linux: ps is usually reliable
      mem_info <- ps::ps_system_memory()
      key <- intersect(c("available", "avail"), names(mem_info))
      val <- if (length(key) > 0) mem_info[[key]] / 1024^3 else NA_real_
  
      if (is.finite(val)) val else {
        # Linux fallback: read /proc/meminfo directly
        if (file.exists("/proc/meminfo")) {
          kb = suppressWarnings(
            as.numeric(system("awk '/MemAvailable/ {print $2}' /proc/meminfo", intern = TRUE))
          )
          if (length(kb) > 0 && !is.na(kb)) kb / 1024^2 else NA_real_
        } else {
          NA_real_
        }
      }
    }
  }, error = function(e) NA_real_)
}

avail_ram_gb = get_ram_gb()

## choose threads conservatively (00 is light; keep headroom) ------------------

reserve_cores   = 1L
gb_per_thread   = 0.50
max_by_cores    = max(1L, all_cores - reserve_cores)
max_by_memory   = if (is.finite(avail_ram_gb)) max(1L, floor(avail_ram_gb / gb_per_thread)) else max_by_cores
n_threads       = as.integer(max(1L, min(max_by_cores, max_by_memory, 8L)))
n_math_threads  = as.integer(max(1L, min(n_threads, 8L)))

## apply thread settings -------------------------------------------------------

data.table::setDTthreads(threads = n_threads)
collapse::set_collapse(nthreads  = n_threads)
options(arrow.use_threads        = TRUE)
Sys.setenv(ARROW_NUM_THREADS     = n_threads)
options(mc.cores                 = n_threads)

# concise summary
message(
  sprintf("Env OK | OS=%s | Cores=%d | Threads=%d | MathThreads=%d | Avail RAMâ‰ˆ%s GB",
          os_type, all_cores, n_threads, n_math_threads,
          ifelse(is.finite(avail_ram_gb), round(avail_ram_gb, 1), "NA"))
)
```
```{r Create Revision Folders}
### file locations -------------------------------------------------------------

if (!dir.exists(paste0(project_location, "/project_tables/revision"))) {
  dir.create(paste0(project_location, "/project_tables/revision"))
}
if (!dir.exists(paste0(project_location, "/project_output/revision"))) {
  dir.create(paste0(project_location, "/project_output/revision"))
}
if (!dir.exists(paste0(project_location, "/project_output/revision/graphs"))) {
  dir.create(paste0(project_location, "/project_output/revision/graphs"))
}
```

```{r Function to Convert Datetimes to Local Time Zone}
#Write Function to Convert Datetime Columns to 'UTC'
fn.timezone_tolocal <- function(df) {
  # Get the dataset schema
  sch <- df$schema
  #Which Fields are Datetime Types?
  datetime_fields <- keep(sch$fields, function(field) {
    grepl("^timestamp", field$type$ToString())
  })
  # Extract the names of these datetime columns
  datetime_cols <- map_chr(datetime_fields, "name")
  
  #Now Convert DateTime Columns to Local Timezone
  df <- df %>%
    mutate(across(all_of(datetime_cols), ~ cast(.x, arrow::timestamp("us", site_time_zone)))) |>
    compute()
}
```


```{r Function to Decompose Table 1 Summaries for 'Easy' Pooling}
tab_decomp <- function(table) {
  
  results_list <- list()  # Prepare an empty list to store results

  
#First Do Continuous Table  
if (!is.null(table$ContTable)) {
  strata <- rownames(table$ContTable)
  for (i in strata) {
    # Extract the relevant names and data for the current strata
    rows <- rownames(table$ContTable[[i]])
    cols <- colnames(table$ContTable[[i]])
    
    x <- as_tibble(table$ContTable[[i]])
    colnames(x) <- cols
    
    # Create a new tibble with the desired structure
    x <- x |>
      mutate(
        strata = i, 
        variable = rows) |>
      relocate(strata, variable, .before = 1)
    
    results_list[[i]] <- x  # Append result to the list
  }
  # Combine all results into a single tibble
  cont_table <- collapse::rowbind(results_list)
  
} else {
  cat('\n No Continuous Table for These Variables\n')
  cont_table <- NULL  # Assign NULL if there are no continuous tables
} 
  #Now Categorical Table
 results_list <- list() #Reinitialize List
if (!is.null(table$CatTable)) {  
    strata <- rownames(table$CatTable)
  for (i in strata) {
    category <- table$MetaData$varFactors
    for (z in category) {
    # Extract the relevant names and data for the current strata
    rows <- rownames(table$CatTable[[i]][[z]])
    cols <- colnames(table$CatTable[[i]][[z]])
    
    x <- as_tibble(table$CatTable[[i]][[z]])
    colnames(x) <- cols
    
    # Create a new tibble with the desired structure
    x <- x |>
      mutate(
        strata = i, 
        variable = z) |>
      relocate(strata, variable, level, .before = 1)
    
    results_list[[length(results_list) + 1]] <- x  # Append result to the list
    }
      }
  # Combine all results into a single tibble
  cat_table <- collapse::rowbind(results_list)
} else {
  cat('\n No Categorical Table for These Variables\n')
  cat_table <- NULL  # Assign NULL if there are no categorical tables
} 
  #Put Two Tables into  a List
  table_list <- list(continuous = cont_table, categorical = cat_table)
  return(table_list)
  }
```


```{r Function to Summarise Logistic Regression Models}
model_summary_table <- function(model) {
 
#Uses Fixed Effects for Hospital in Sites with > 1 Hospital (and clustered standard errors)  
if (n_hospitals>1) {
  #Cluster Robust Standard Errors Using LM Test
  coef_table <- coeftest(model, 
                         vcovCL(model, cluster = model.frame(model)$hospital_id)) 
  # Cluster-robust covariance matrix
  clustered_se <- vcovCL(model, cluster = model.frame(model)$hospital_id)
  #Compute confidence intervals manually using the clustered SE
  conf_int <- coefci(model, vcov. = clustered_se)
}  else {
  coef_table <- coeftest(model)
  conf_int <- coefci(model)
}
 model_table <- data.frame(
  'site' = site,
  'n_observations' = nobs(model),
  'term' = rownames(coef_table),
  'estimate' = coef_table[, "Estimate"],
  'std_error' = coef_table[, "Std. Error"],
  'p_value' = coef_table[, "Pr(>|z|)"],
  'odds_ratio' = round(exp(coef_table[, "Estimate"]), 3),  # Exponentiated coefficients as Odds Ratios
  'lower_bound' = exp(conf_int[, 1]),  # Lower bound of CI from coefci()
  'upper_bound' = exp(conf_int[, 2])   # Upper bound of CI from coefci()
)
model_table <- model_table |>
  mutate(confidence_interval=paste0(round(lower_bound, 3), ' - ', round(upper_bound, 3))) |>
  mutate(n_hospitals=n_hospitals) |>
  relocate(confidence_interval, .before = lower_bound) |>
  relocate(n_hospitals, .after = n_observations) 
  rownames(model_table) <- NULL
return(model_table)
}

#Create a Function to Also Make Tables that Contain the Average Marginal Effects: THis Uses the maringaleffects::avg_slopes() function and using the'type==response' option yields estimates on the fraction scale (i.e, 0.1 is 10% absolute increase)
ame_summary <- function(model_list) {
  results <- list()  # Initialize an empty list to store results
  
  for (i in 1:length(model_list)) {
    # Extract the model formula as a single string
    formula_string <- paste(deparse(model_list[[i]]$formula), collapse = " ")
    
    # Compute and tidy the avg_slopes for the model
    slopes <- tidy(avg_slopes(model_list[[i]], type = "response"))
    
    # Add a column indicating the model index
    slopes <- slopes %>%
      mutate(model = paste0("Model ", i)) %>%
      mutate(across(c("estimate", "conf.low", "conf.high"), \(x) round(x, 4)))
    
    # Check if the model formula contains ':month_scaled' (interaction term)
    # Need to Also Check if this a Two Period Model (will have 'covid_period' in it)
    if (grepl("study_period:month_scaled", formula_string, ignore.case = TRUE)) {
      # Additional avg_slopes computation for interaction terms
      additional_slopes <- tidy(avg_slopes(model_list[[i]], variables = "month_scaled", by = "study_period")) %>%
        mutate(model = paste0("Model ", i, " - Interaction Terms")) %>%
        mutate(across(c("estimate", "conf.low", "conf.high"), \(x) round(x, 4)))
      
      # Combine the main slopes with additional slopes
      slopes <- bind_rows(slopes, additional_slopes)
    } else if (grepl("period_sarscov2_post:month_scaled", 
                     formula_string, ignore.case = TRUE)) {
      # Additional avg_slopes computation for interaction terms
      additional_slopes <- tidy(avg_slopes(model_list[[i]], variables = "month_scaled", by = "period_sarscov2_post")) %>%
        mutate(model = paste0("Model ", i, " - Interaction Terms")) %>%
        mutate(across(c("estimate", "conf.low", "conf.high"), \(x) round(x, 4)))
      
      # Combine the main slopes with additional slopes
      slopes <- bind_rows(slopes, additional_slopes)
    } else if (grepl("covid_period:month_scaled", formula_string, ignore.case = TRUE)) {
      
      # Additional avg_slopes computation for interaction terms
      additional_slopes <- tidy(avg_slopes(model_list[[i]], variables = "month_scaled", by = "covid_period")) %>%
        mutate(model = paste0("Model ", i, " - Interaction Terms")) %>%
        mutate(across(c("estimate", "conf.low", "conf.high"), \(x) round(x, 4)))
      
      # Combine the main slopes with additional slopes
      slopes <- bind_rows(slopes, additional_slopes)
    }
    
    # Add the result to the list
    results[[i]] <- slopes
    
    # Add an empty row to separate models (if not the last model)
    if (i < length(model_list)) {
      empty_row <- data.frame(matrix(NA, nrow = 1, ncol = ncol(slopes)))
      colnames(empty_row) <- colnames(slopes)
      empty_row$model <- NA  # Ensure model column exists
      results[[i]] <- bind_rows(results[[i]], empty_row)
    }
  }
  
  # Bind all results together into one table
  final_results <- bind_rows(results)
  
  return(final_results)  # Return the final combined table
}
```

```{r Open Analytic Data}
#NOTE: This Table is Created by the 00_file if you need to regenerate
prone_analytic_df <- read_parquet(paste0(project_location, '/project_tables/prone_analytic_data.parquet')) 

#Apply Function to Convert to Local Timezone

#Load Cohort_ids
load(paste0(project_location, '/project_tables/cohort_hospitalization_ids.RData')) 
cohort_hospitalization_ids <- cohort_hospitalization_ids |>
  mutate(hospitalization_id=as.character(hospitalization_id))

```

```{r Define Study Months/Quarters}
#Further Define sex_category as female 1, male/other/unknown 0
prone_analytic_df <- prone_analytic_df |>
  mutate(female=fifelse(tolower(sex_category)=='female', 1, 0)) |>
  #Define Calendar Time for Time of Enrollment
  mutate(year=year(t_enrollment)) |>
  mutate(calendar_month=month(t_enrollment)) |>
  arrange(year, calendar_month)

#Report Out Minimum and Maximum Times
cat('At', site, 'the first eligible patient was enrolled on', as.character(first(prone_analytic_df$t_enrollment)), 
    '\n and the last on', as.character(last(prone_analytic_df$t_enrollment)))

#Create a Study Month Data Frame to Merge to Create Study Month; Can Adjust ym() to accomadte desired period; for this analysis 2018 through 2024
study_month <- data.frame(start_date=seq(ym("201801"), ym("202412"), by= "months")) |>
  mutate(calendar_month=month(start_date)) |>
  mutate(year=year(start_date)) |>
  arrange(year, calendar_month) |>
  mutate(study_month=seq(1:n())) |>
  select(-start_date) |>
  mutate(study_quarter=ceiling(study_month/3))

#Now Merge to Prone Analytic_DF
prone_analytic_df <- prone_analytic_df |>
  left_join(study_month) 
 
#Define the Pre-Specified Study Periods
#Jan 2018-Feb 2020 'Pre-COVID', March 2020-February 2022 'COVID', March 2022-December 2023 'Post_COVID'
#So that All Sites Can Participate Will use the COVID Period as The Reference
prone_analytic_df <- prone_analytic_df |>
  mutate(study_period=fcase(
    study_month>=1 & study_month<27, 'Pre-COVID',
    study_month>=27 & study_month<51, 'COVID',
    study_month>=51, 'Post-COVID'
  )) |>
  mutate(study_period_cat=factor(study_period,
                               levels = c("COVID", "Pre-COVID", "Post-COVID"),
                               labels = c(1, 2, 3)))

#In this script we keep track of the minimum and maximum study month both for graphs and for the modelling
min_month <- min(prone_analytic_df$study_month)
max_month <- max(prone_analytic_df$study_month)
min_quarter <- min(prone_analytic_df$study_quarter)
max_quarter <- max(prone_analytic_df$study_quarter)

#Create 'site_type' vector that shows Which study periods are Included
site_type <- prone_analytic_df |>
  distinct(study_period) 
site_type <- paste(site_type$study_period, collapse = ",")
#Possible Combinations are "Pre-COVID,COVID,Post-COVID"|"COVID,Post-COVID"|"Pre-COVID,"COVID"

#Keep Track of the Number of Hospitals
n_hospitals <- length(unique(prone_analytic_df$hospital_id[!is.na(prone_analytic_df$hospital_id)]))

#Create a Few More Variables
prone_analytic_df <- prone_analytic_df |>
  mutate(admit_to_enrolled=as.duration(t_enrollment-final_admission_dttm)/dhours(1)) |>
  mutate(ett_to_enrolled=as.duration(t_enrollment-vent_episode_start)/dhours(1)) |>
  mutate(severe_ards=fifelse(min_pf_ratio<100, 1, 0))

#Create a 'Unknown' Category for SARS COV2 - THis is if we can't confirm a positive or negative SARS-Cov2 test in the COVID or Post-COVID era
prone_analytic_df <- prone_analytic_df |>
  mutate(sars_cov2_positive=fcase(
    sars_cov2_positive==1, 'Positive', 
    sars_cov2_positive==0, 'Negative',
    study_period_cat %in% c(1, 3) & is.na(sars_cov2_positive), 'Unknown',
    study_period_cat %in% c(2), 'Pre-COVID'
  )) |>
  #Create Period-Sars-COV2 Status Categorical Variables - For Categorical Variable COVID-Negative Could be Reference
  mutate(period_sarscov2=fcase(
    study_period_cat==2, 'Pre-COVID', 
    study_period_cat==1 & sars_cov2_positive=='Positive', 'COVID_SarsCov2Pos',
    study_period_cat==1 & sars_cov2_positive %in% c('Negative', 'Unknown'), 'COVID_SarsCov2Neg-Unk',
    study_period_cat==3 & sars_cov2_positive=='Positive','Post-COVID_SarsCov2Pos',
    study_period_cat==3 & sars_cov2_positive %in% c('Negative', 'Unknown'), 'Post-COVID_SarsCov2Neg-Unk'
  )) |>
  #Given the POST-covid Sars_cov2 + is a small population will collapse that into post-COVID for some analysis, COVID-Negative is Reference
  mutate(period_sarscov2_post=fcase(
    study_period_cat==2, 'Pre-COVID', 
    study_period_cat==1 & sars_cov2_positive=='Positive', 'COVID_SarsCov2Pos',
    study_period_cat==1 & sars_cov2_positive %in% c('Negative', 'Unknown'), 'COVID_SarsCov2Neg-Unk',
    study_period_cat==3,'Post-COVID'
  ))

#To Aid In Intrepretability Plan to Scale Each of The Continuous Variables
#Will Use Global Mean from Preliminary Data to Center Each Variable and then Scale by Reasonable Delta
prone_analytic_df <- prone_analytic_df |>
  mutate(
    age_scale=(age_at_admission-60)/10,
    bmi_scale=(bmi-30)/5,
    min_pf_ratio_scale=(min_pf_ratio-80)/10,
    sofa_score_scale=(sofa_score-9),
    month_scaled=study_month/3)
```

```{r Add ARDS Diagnostic Codes}
diagnosis <- open_dataset(paste0(tables_location, '/clif_hospital_diagnosis.parquet')) |>
  mutate(hospitalization_id=as.character(hospitalization_id)) |>
  dplyr::semi_join(cohort_hospitalization_ids) |>
  dplyr::left_join(cohort_hospitalization_ids) |>
  collect() |>
  mutate(
    ards_code=fifelse(
      grepl('j80', diagnosis_code, ignore.case=T), 1, 0),
    chf_code=fifelse(
      grepl('i50', diagnosis_code, ignore.case=T), 1, 0)
    ) |>
  group_by(patient_id, encounter_block) |>
  mutate(
    #1st Definition ARDS Code but No CHF Code
    ards_icd_10=fifelse(
      sum(ards_code, na.rm=T)>=1, 1, 0, 0
    ))|>
  ffirst() |>
  select(patient_id, encounter_block, ards_icd_10) |>
  distinct()

prone_analytic_df <- prone_analytic_df |>
  left_join(diagnosis)

#Prone by Diagnostic Code per Period
#Create a Table of N of Patients and Number Proned Per Study Month Per Hospital
prone_per_ards_icd <- prone_analytic_df |> 
  group_by(study_period, ards_icd_10) |>
  summarise(
    'site' = site,
    'n_hospitals' = n_hospitals,
    'n_patients' = n(),
    'n_proned_12_hr' = sum(prone_12hour_outcome),
    'proned_12_hr_percent' = mean(prone_12hour_outcome),
    'standard_error_12' = sqrt(mean(prone_12hour_outcome) * (1 - mean(prone_12hour_outcome)) / n()),
    'n_proned_24_hr' = sum(prone_24hour_outcome),
    'proned_24_hr_percent' = mean(prone_24hour_outcome),
    'standard_error_24' = sqrt(mean(prone_24hour_outcome) * (1 - mean(prone_24hour_outcome)) / n()),
    'n_proned_72_hr' = sum(prone_72hour_outcome),
    'proned_72_hr_percent' = mean(prone_72hour_outcome),
    'standard_error_72' = sqrt(mean(prone_72hour_outcome) * (1 - mean(prone_72hour_outcome)) / n()),
    'n_proned_all' = sum(proned),
    'proned_percent_all' = mean(proned),
    'standard_error_all' = sqrt(mean(proned) * (1 - mean(proned)) / n())
  ) 
write_csv(prone_per_ards_icd, paste0(project_location, '/project_output/revision/', site,'_prone_per_period_ards_icd.csv'))
```


```{r Adjusted Regression with ARDS ICD-10 Code}
#Agreed Upon Covariates (see DAG): Age, Gender, BMI, PF Ratio, Norepi Equivalents, sofa_score, hospital

#Full Model - Add Adjustement for ARDS ICD-10
model_form_step <- prone_12hour_outcome ~ study_period + ards_icd_10 + age_scale + female + bmi_scale + factor(nee_pressor_dose) + sofa_score_scale +  
  min_pf_ratio_scale + factor(hospital_id)
#Now Modified for Each Site
if (n_hospitals > 1) {
  # Keep the formula as is
  model_form_step <- model_form_step
} else if (n_hospitals == 1) {
  # Remove 'factor(hospital_id)'
  model_form_step <- update(model_form_step, . ~ . - factor(hospital_id))
}

multivar_mod_wicd10 <- glm(model_form_step,
          data = prone_analytic_df, 
          family=binomial)
summary(multivar_mod_wicd10)
multivar_mod_summary_wicd10 <- model_summary_table(multivar_mod_wicd10)


#Full Model - Stratified by ARDS ICD10
model_form_step <- prone_12hour_outcome ~ study_period + age_scale + female + bmi_scale + factor(nee_pressor_dose) + sofa_score_scale +  
  min_pf_ratio_scale + factor(hospital_id)
#Now Modified for Each Site
if (n_hospitals > 1L) {
  # Keep the formula as is
  model_form_step <- model_form_step
} else if (n_hospitals == 1L) {
  # Remove 'factor(hospital_id)'
  model_form_step <- update(model_form_step, . ~ . - factor(hospital_id))
}

multivar_mod_ards_by_icd <- glm(model_form_step,
          data = subset(prone_analytic_df, ards_icd_10==1), 
          family=binomial)
summary(multivar_mod_ards_by_icd)
multivar_mod_summary_ards_by_icd <- model_summary_table(multivar_mod_ards_by_icd)

multivar_mod_no_ards_by_icd <- glm(model_form_step,
          data = subset(prone_analytic_df, ards_icd_10==0 | is.na(ards_icd_10)), 
          family=binomial)
summary(multivar_mod_no_ards_by_icd )
multivar_mod_summary_no_ards_by_icd <- model_summary_table(multivar_mod_no_ards_by_icd )


multivar_table <- bind_rows(
  data.frame('site'=c('','Adjusted Model With ARDS ICD-10 Adjustment')),
  multivar_mod_summary_wicd10, 
  data.frame('site'=c('','Adjusted Model Restricted to Those with ICD-10 ARDS')),
  multivar_mod_summary_ards_by_icd, 
  data.frame('site'=c('','Adjusted Model Restricted to Those without ICD-10 ARDS (')),
  multivar_mod_summary_no_ards_by_icd)
# Write the table to a CSV file
write.csv(multivar_table, paste0(project_location, '/project_output/revision/', site, '_adjusted_models_ards_icd10s.csv'))

#Output a Table of Average Marginal Effects Using the AME Function Created Above
model_list <- list(multivar_mod_wicd10, 
                   multivar_mod_ards_by_icd, 
                   multivar_mod_no_ards_by_icd)
multivar_ame <- ame_summary(model_list)
write.csv(multivar_ame, paste0(project_location, '/project_output/revision/', site, '_adjusted_ame_by_ards_icd.csv'))

```

```{r Adjusted Models Moderate ARDS}
#This is to Complement the Already Completed Severe ARDS Models
#First Output Summary Table by ARDS Severity
prone_per_ards_severity <- prone_analytic_df |> 
  group_by(study_period, severe_ards) |>
  summarise(
    'site' = site,
    'n_hospitals' = n_hospitals,
    'n_patients' = n(),
    'n_proned_12_hr' = sum(prone_12hour_outcome),
    'proned_12_hr_percent' = mean(prone_12hour_outcome),
    'standard_error_12' = sqrt(mean(prone_12hour_outcome) * (1 - mean(prone_12hour_outcome)) / n()),
    'n_proned_24_hr' = sum(prone_24hour_outcome),
    'proned_24_hr_percent' = mean(prone_24hour_outcome),
    'standard_error_24' = sqrt(mean(prone_24hour_outcome) * (1 - mean(prone_24hour_outcome)) / n()),
    'n_proned_72_hr' = sum(prone_72hour_outcome),
    'proned_72_hr_percent' = mean(prone_72hour_outcome),
    'standard_error_72' = sqrt(mean(prone_72hour_outcome) * (1 - mean(prone_72hour_outcome)) / n()),
    'n_proned_all' = sum(proned),
    'proned_percent_all' = mean(proned),
    'standard_error_all' = sqrt(mean(proned) * (1 - mean(proned)) / n())
  ) 
write_csv(prone_per_ards_severity, paste0(project_location, '/project_output/revision/', site,'_prone_per_ards_severity.csv'))


#Full Model
model_form_step <- prone_12hour_outcome ~ study_period + age_scale + female + bmi_scale + factor(nee_pressor_dose) + sofa_score_scale +  
  min_pf_ratio_scale + factor(hospital_id)
#Now Modified for Each Site
if (n_hospitals > 1) {
  # Keep the formula as is
  model_form_step <- model_form_step
} else if (n_hospitals == 1) {
  # Remove 'factor(hospital_id)'
  model_form_step <- update(model_form_step, . ~ . - factor(hospital_id))
}

multivar_mod <- glm(model_form_step,
          data = subset(prone_analytic_df, severe_ards==0), 
          family=binomial)
summary(multivar_mod)
multivar_mod_summary <- model_summary_table(multivar_mod)

# Write the table to a CSV file
write.csv(multivar_mod_summary, paste0(project_location, '/project_output/revision/', site, '_adjusted_models_moderate_ards.csv'))

#Output a Table of Average Marginal Effects Using the AME Function Created Above
model_list <- list(multivar_mod)
multivar_ame <- ame_summary(model_list)
write.csv(multivar_ame, paste0(project_location, '/project_output/revision/', site, '_adjusted_ame_moderate_ards.csv'))
```


```{r Resp Support for TV, PEEP, Driving Pressure, Set and Observed RR}
#Define Vent Support Variables in The Period Between Vent Start and t_enrollment
#Take Variable Closest to t_enrollment
vent_times <- prone_analytic_df |>
  select(patient_id, encounter_block, study_height_cm,female, vent_episode_start, t_enrollment, study_period, prone_12hour_outcome)

#Get CLIF Resp
clif_resp <- open_dataset(paste0(tables_location, '/clif_respiratory_support.parquet')) |>
  mutate(hospitalization_id=as.character(hospitalization_id)) |>
  select(hospitalization_id, recorded_dttm, device_category, mode_category, fio2_set, tidal_volume_set, tidal_volume_obs, resp_rate_set, resp_rate_obs, peep_set, peak_inspiratory_pressure_obs, plateau_pressure_obs) |>
  dplyr::semi_join(cohort_hospitalization_ids) |>
  dplyr::left_join(cohort_hospitalization_ids) |>
  dplyr::left_join(vent_times) |>
  #Only Need to Keep the Time After Vent Start
  dplyr::filter(recorded_dttm>=vent_episode_start) |>
  dplyr::distinct() |>
  collect()

#Preapre a Flowsheet for Ventilator Practices
#Vent Modes for Set Tidal Volume
set_tv <- c(
  'Assist Control-Volume Control',
  'Pressure-Regulated Volume Control',
  'Volume Support'
)

exhaled_tv <- c(
  'Pressure Control',
  'Pressure Support/CPAP',
  'SIMV',
  'Other'
)
vent_practices <- clif_resp |>
  #Label Values as Before or After Vent
  mutate(before_enrollment=fifelse(recorded_dttm<t_enrollment, 1, 0)) |>
  #Carry Forward Mode Category within Device Categories
  group_by(patient_id, encounter_block) |>
  dplyr::arrange(patient_id, encounter_block, recorded_dttm) |>
  fill(device_category, .direction='down') |>
  group_by(patient_id, encounter_block, device_category) |>
  fill(mode_category, .direction='down') |>
  #Carry Forward PEEP on Same Modes
  group_by(patient_id, encounter_block, mode_category) |>
  fill(peep_set, .direction = 'down') |>
  ungroup() |>
  #Calculate Some Needed Variables
  mutate(
   #FOr Those That are Less Than 5 Feet Use Modifiation of IBW set at that of a 5 foot person
   #Study Height CM Outlier
   study_height_cm=fifelse(
     study_height_cm>243 | study_height_cm<76, NaN,
     study_height_cm),
   height_inches=study_height_cm/2.54, 
   ibw=data.table::fcase(
      female==0, 50 + 2.3*(height_inches-60),
      female==1, 45.5 + 2.3*(height_inches-60)),
    ibw=dplyr::if_else(
       female==0 & study_height_cm<152.4, 50, ibw),
    ibw=dplyr::if_else(
       female==1 & study_height_cm<152.4, 45.5, ibw),
   tidal_volume=fcase(
     mode_category %in% set_tv, tidal_volume_set,
     mode_category %in% exhaled_tv, tidal_volume_obs)) 

#Address Physiologic Improbable Outliers
vent_practices <- vent_practices |>
  #Tidal Volume
  mutate(
    tidal_volume=fifelse(
      tidal_volume>1500 | tidal_volume<150, NaN, 
      tidal_volume
    ),
    tv_pbw=tidal_volume/ibw,
    peep_set=fifelse(peep_set>=35, NaN, peep_set),
    plateau_pressure_obs=
      fifelse(plateau_pressure_obs>=60 | 
            plateau_pressure_obs<=5, NaN, plateau_pressure_obs),
    peak_inspiratory_pressure_obs=fifelse(
         peak_inspiratory_pressure_obs>100 | 
           (!is.na(peep_set) & peak_inspiratory_pressure_obs<=peep_set) |
    peak_inspiratory_pressure_obs<=5, NaN, peak_inspiratory_pressure_obs),
    static_dp=fifelse(
      plateau_pressure_obs-peep_set>=5, plateau_pressure_obs-peep_set, NaN))

#Now Obtain Value Closest to t_enrollment as Baseline Value
vent_summary <- vent_practices |>
  filter(before_enrollment==1) |>
  #Order with Latest Time First
  arrange(patient_id, encounter_block, desc(recorded_dttm))

#Now the Variables we Want to Summarize
summary_variables <- c(
  "tidal_volume", 
  "tv_pbw", 
  "peak_inspiratory_pressure_obs",
  "plateau_pressure_obs",
  "peep_set",
  "static_dp",
  "resp_rate_set",
  "resp_rate_obs")  

# Using rowwise to apply coalesce across the selected variables
vent_summary <- vent_summary |>
  group_by(patient_id, encounter_block) |>
  # Fill missing values in summary_variables
  fill(all_of(summary_variables), .direction = 'up') |>
  # Get only the first row for each group
  group_by(patient_id, encounter_block) |>
  mutate(rn=dplyr::row_number()) |>
  filter(rn==1) |>
  ungroup() |>
  select(patient_id, encounter_block, study_period, prone_12hour_outcome, summary_variables) |>
  #Static Respiratory Compliance
  mutate(static_compliance=tidal_volume/static_dp)
```
```{r Sedation Practices - RASS, Drips and Paralysis}
#RASS Score
rass_table <- open_dataset(paste0(tables_location, '/clif_patient_assessments.parquet')) |>
  mutate(hospitalization_id=as.character(hospitalization_id)) |>
  filter(tolower(assessment_category)=='rass') |>
  select(hospitalization_id, recorded_dttm, rass=numerical_value) |>
  dplyr::semi_join(cohort_hospitalization_ids) |>
  dplyr::left_join(cohort_hospitalization_ids) |>
  dplyr::left_join(vent_times) |>
  dplyr::filter(
    recorded_dttm>=vent_episode_start,
    recorded_dttm<t_enrollment,
    rass>=-5 & rass<=4) |>
  dplyr::distinct() |>
  collect() |>
  group_by(patient_id, encounter_block) |>
  arrange(patient_id, encounter_block, desc(recorded_dttm)) |>
  group_by(patient_id, encounter_block) |>
  # Get only the first row for each group
  group_by(patient_id, encounter_block) |>
  mutate(rn=dplyr::row_number()) |>
  filter(rn==1) |>
  ungroup() |>
  select(patient_id, encounter_block, rass) 

#Paralytics and Sedation
med_continuous <- open_dataset(paste0(tables_location, '/clif_medication_admin_continuous.parquet')) |>
  mutate(hospitalization_id=as.character(hospitalization_id)) |>
  filter(tolower(med_group) %in% c(
    'paralytics',
    'sedation',
    'pulmonary vasodilators (inhaled)'),
    tolower(med_route_category) %in% c('intravenous', 'inhaled', 'iv'),
    !is.na(med_dose),
    #Filter Out Med Dose Units That Don't Indicate a Drip) 
    !med_dose_unit %in% c(
      'mg',
      'mcg') & !is.na(med_dose_unit)) |>
  select(hospitalization_id, admin_dttm, med_group, med_category, med_dose, med_dose_unit) |>
  dplyr::semi_join(cohort_hospitalization_ids) |>
  dplyr::left_join(cohort_hospitalization_ids) |>
  dplyr::left_join(vent_times) |>
  dplyr::filter(
    admin_dttm>=vent_episode_start,
    admin_dttm<t_enrollment) |>
  collect() |>
  #Select Last Dose Prior to T-Enrollment for Each Med
  group_by(patient_id, encounter_block, med_category) |>
  arrange(patient_id, encounter_block, med_category, desc(admin_dttm)) |>
  group_by(patient_id, encounter_block, med_category) |>
  dplyr::filter(dplyr::row_number()==1) |>
  ungroup() |>
  #Now go to wide Table with Med and Dose
  select(patient_id, encounter_block, med_category, med_dose) |>
  pivot_wider(
    names_from = med_category,
    values_from = med_dose,
    id_cols=c(patient_id, encounter_block),
    values_fill = 0
  ) 

#Now Need to Make SUre All Potential Meds have a Column
# Define the desired infusion columns
desired_infusion_columns <- c(
  "fentanyl", "remifentanyl", "morphine", "hydromorphone",
  "vecuronium", "cisatracurium", "rocuronium", 
  "ketamine", "propofol", 
  "nitric_oxide", "epoprostenol",
  "midazolam", "lorazepam", 
  "dexmedetomidine",
  "opiate_infusion", 
  "nmb_infusion", 
  "ketamine_infusion", 
  "propofol_infusion", 
  "inh_pulm_vasodilator", 
  "benzo_infusion", 
  "dexmed_infusion"
)

missing_columns <- setdiff(desired_infusion_columns, names(med_continuous))

for (column in missing_columns) {
  med_continuous[[column]] <- 0
}

#Now for Each Med/Med Group Define Whether Infusion Was On at Time of Enrollment
med_continuous <- med_continuous |>
  mutate(
    opiate_infusion=fifelse(
      fentanyl>0 | remifentanyl>0 | morphine>0 | hydromorphone>0, 1, 0, 0),
    nmb_infusion=fifelse(
      vecuronium>0 | cisatracurium>0 | rocuronium>0, 1, 0, 0),
    ketamine_infusion=fifelse(
      ketamine>0, 1, 0, 0), 
    propofol_infusion=fifelse(
      propofol>0, 1, 0, 0),
    inh_pulm_vasodilator=fifelse(
      nitric_oxide>0 | epoprostenol>0, 1, 0, 0),
    benzo_infusion=fifelse(
      midazolam>0 | lorazepam>0, 1, 0, 0),
    dexmed_infusion=fifelse(
      dexmedetomidine>0, 1, 0, 0))
```


```{r Summarize the Vent/Sedation/Paralysis Variables}
vent_table_sum <- prone_analytic_df |>
  select(patient_id, encounter_block) |> #Start with all patients
  left_join(vent_summary) |>
  left_join(rass_table) |>
  left_join(med_continuous) |>
  # Set any missing meds to 0
  mutate(across(.cols = all_of(desired_infusion_columns), ~ replace_na(., 0)))

#Now Summarise: Overall, By Proning Status, By Period, and By Period and Proning Status
to_tab <- c(
  "tidal_volume", 
  "tv_pbw", 
  "peak_inspiratory_pressure_obs",
  "plateau_pressure_obs",
  "peep_set",
  "static_dp",
  "static_compliance",
  "resp_rate_set",
  "resp_rate_obs",
  "rass",
  "opiate_infusion",
  "nmb_infusion",
  "ketamine_infusion",
  "propofol_infusion",
  "inh_pulm_vasodilator",
  "benzo_infusion",
  "dexmed_infusion")  

factors_tab <- c(
  "opiate_infusion",
  "nmb_infusion",
  "ketamine_infusion",
  "propofol_infusion",
  "inh_pulm_vasodilator",
  "benzo_infusion",
  "dexmed_infusion"
)

vent_table <- CreateTableOne(
  data=vent_table_sum, 
  vars=to_tab, 
  factorVars=factors_tab,
  strata='study_period', 
  addOverall = T)

summary(vent_table)
table_list <- tab_decomp(vent_table)
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_vent_summary_by_period.csv'))
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_vent_summary_by_period_infusions.csv'))

vent_table <- CreateTableOne(
  data=vent_table_sum, 
  vars=to_tab, 
  factorVars=factors_tab,
  strata='prone_12hour_outcome', 
  addOverall = F)

summary(vent_table)
table_list <- tab_decomp(vent_table)
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_vent_summary_by_proned.csv'))
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_vent_summary_by_proned_infusion.csv'))

#Create a Period Proned Category Variable
vent_table_sum <- vent_table_sum  |>
  mutate(period_proned=paste0(study_period,'_',prone_12hour_outcome))

vent_table <- CreateTableOne(
  data=vent_table_sum, 
  vars=to_tab, 
  factorVars = factors_tab,
  strata='period_proned',
  addOverall = F)

summary(vent_table)
table_list <- tab_decomp(vent_table)
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_vent_summary_by_proned_period.csv'))
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_vent_summary_by_proned_period_infusion.csv'))

```


```{r Define Patient Outcomes by Period and Proning Status}
#Patient Outcomes: 28-day In-hospital Mortality, In-hospital Mortality, IN-hospital Mortality, In-hospital Mortality and/or DC to Hospice, VFDs at day 28, DC to Hospice, Length of Stay
#Stratified by Period, Proning, Proning and Period

#First Define Outcomes
outcomes_df <- prone_analytic_df |>
  select(patient_id, encounter_block, prone_12hour_outcome, study_period, final_admission_dttm, final_discharge_dttm, t_enrollment, in_hosp_death, death_or_hospice) |>
  mutate(
    #HOSP LOS from T0
    hosp_los_days = as.duration(final_discharge_dttm-t_enrollment)/ddays(1),
    death_day28=fifelse(
      in_hosp_death==1 & hosp_los_days<=29, 1, 0, 0
    ),
     death_hospice_day28=fifelse(
      death_or_hospice==1 & hosp_los_days<=29, 1, 0, 0
    )
  )

#Now Use Respiratory Table To Calculate VFDs (0 if patient days by end of day 28, otherwise number of days with no IMV from t_enrollment
#1 Need to Determine if Someone is Discharged on Vent (if Last device category is vent)
dc_on_vent <- clif_resp |>
  filter(!is.na(device_category)) |>
  select(patient_id, encounter_block, recorded_dttm, device_category) |>
  group_by(patient_id, encounter_block) |>
  arrange(patient_id, encounter_block, recorded_dttm) |>
  filter(
    dplyr::row_number()==dplyr::n()
  ) |>
  ungroup() |>
  mutate(dc_on_vent=fifelse(tolower(device_category)=='imv', 1, 0)) |>
  select(patient_id, encounter_block, dc_on_vent)

#Now Define VFDs through Day 28
vfds <- clif_resp |>
  select(patient_id, encounter_block, recorded_dttm, device_category) |>
  left_join(outcomes_df) |>
  left_join(dc_on_vent) |>
  filter(
    tolower(device_category)=='imv',
    recorded_dttm>=t_enrollment
    ) |>
  mutate(
    day=floor(as.duration(recorded_dttm-t_enrollment)/ddays(1)) + 1
  ) |>
  group_by(patient_id, encounter_block, day) |>
  filter(
    dplyr::row_number()==1,
    day<=28     
    ) |>
  group_by(patient_id, encounter_block) |>
  mutate(
    days_of_imv=dplyr::n()
  ) |>
  filter(
    dplyr::row_number()==1
  ) |>
  ungroup() |>
  #Now Have a Dataset with Number of Days Through Day 28 with IMV Recorded
  #Now Define VFDs
  mutate(
    vfds_day28=fcase(
      death_day28==1, 0, #IF Dead by Day 28 than 0
      hosp_los_days>=29, 28-days_of_imv,
      hosp_los_days<29 & dc_on_vent==1, 0, #If discharged on vent assume stayed on vent
      hosp_los_days<29 & dc_on_vent==0, 28-days_of_imv #If dsicharged OFF vent assumed stayed off vent
    )
  ) |>
  select(patient_id, encounter_block, dc_on_vent, vfds_day28)

#Combined with Outcomes Table
outcomes_df <- outcomes_df |>
  full_join(vfds) |>
  mutate(period_proned=paste0(study_period,'_',prone_12hour_outcome))
```

```{r Create Patient Outcomes Tables}
to_tab <- c(
  'in_hosp_death',
  'death_or_hospice',
  'hosp_los_days',
  'death_day28',
  'death_hospice_day28',
  'vfds_day28'
)

factors_tab <- c(
  'in_hosp_death',
  'death_or_hospice',
  'death_day28',
  'death_hospice_day28'
)

outcomes_table <- CreateTableOne(
  data=outcomes_df, 
  vars=to_tab, 
  factorVars=factors_tab,
  strata='prone_12hour_outcome', 
  addOverall = T)

summary(outcomes_table)
table_list <- tab_decomp(outcomes_table)
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_cont_outcomes_by_proning.csv'))
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_cat_outcomes_by_proning.csv'))

#Now by Period
outcomes_table <- CreateTableOne(
  data=outcomes_df, 
  vars=to_tab, 
  factorVars=factors_tab,
  strata='study_period', 
  addOverall = T)

summary(outcomes_table)
table_list <- tab_decomp(outcomes_table)
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_cont_outcomes_by_period.csv'))
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_cat_outcomes_by_period.csv'))

#Now by Proning and Period
outcomes_table <- CreateTableOne(
  data=outcomes_df, 
  vars=to_tab, 
  factorVars=factors_tab,
  strata='period_proned', 
  addOverall = T)

summary(outcomes_table)
table_list <- tab_decomp(outcomes_table)
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_cont_outcomes_by_proned_period.csv'))
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_cat_outcomes_by_proned_period.csv'))
```
```{r Evalute Proning Duration as Categorical Variable}
prone_analytic_df <- prone_analytic_df |>
  mutate(
    first_prone_episode_cat = case_when(
      first_prone_episode_hours <= 12 ~ "<=12 hours",
      first_prone_episode_hours > 12 & first_prone_episode_hours <= 16 ~ "12-16 hours",
      first_prone_episode_hours > 16 & first_prone_episode_hours <= 24 ~ "16-24 hours",
      first_prone_episode_hours > 24 & first_prone_episode_hours <= 48 ~ "24-48 hours",
      first_prone_episode_hours > 48 ~ ">48 hours",
      TRUE ~ NA_character_
    ),
    mean_pt_prone_cat = case_when(
      mean_pt_prone_duration <= 12 ~ "<=12 hours",
      mean_pt_prone_duration > 12 & mean_pt_prone_duration <= 16 ~ "12-16 hours",
      mean_pt_prone_duration > 16 & mean_pt_prone_duration <= 24 ~ "16-24 hours",
      mean_pt_prone_duration > 24 & mean_pt_prone_duration <= 48 ~ "24-48 hours",
      mean_pt_prone_duration > 48 ~ ">48 hours",
      TRUE ~ NA_character_
    ),
    median_pt_prone_cat = case_when(
      median_pt_prone_duration <= 12 ~ "<=12 hours",
      median_pt_prone_duration > 12 & median_pt_prone_duration <= 16 ~ "12-16 hours",
      median_pt_prone_duration > 16 & median_pt_prone_duration <= 24 ~ "16-24 hours",
      median_pt_prone_duration > 24 & median_pt_prone_duration <= 48 ~ "24-48 hours",
      median_pt_prone_duration > 48 ~ ">48 hours",
      TRUE ~ NA_character_
    )
  ) |>
  mutate(across(
    c(first_prone_episode_cat, mean_pt_prone_cat, median_pt_prone_cat),
    ~ factor(., levels = c("<=12 hours", "12-16 hours", "16-24 hours", "24-48 hours", ">48 hours"), 
             ordered = TRUE)
  ))

to_tab <- c(
  'first_prone_episode_hours',
  'mean_pt_prone_duration',
  'median_pt_prone_duration',
  'first_prone_episode_cat',
  'mean_pt_prone_cat',
  'median_pt_prone_cat'
)

factors_tab <- c(
  'first_prone_episode_cat',
  'mean_pt_prone_cat',
  'median_pt_prone_cat'
)

prone_duration_table <- CreateTableOne(
  data=prone_analytic_df, 
  vars=to_tab, 
  factorVars=factors_tab,
  strata='study_period', 
  addOverall = T)

summary(prone_duration_table)
table_list <- tab_decomp(prone_duration_table)
write_csv(table_list$categorical, paste0(project_location, '/project_output/revision/', site, '_prone_duration_categorical.csv'))
write_csv(table_list$continuous, paste0(project_location, '/project_output/revision/', site, '_prone_duration_continuous.csv'))

```

